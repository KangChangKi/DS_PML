---
title: "Classifying Barbell Lifts from the Data of Accelerometers"
author: "Kang Chang Ki"
date: "September 21, 2015"
output:
        html_document:
                fig_caption: yes
---

## Background

With the advance of methods like HAR or Human Activity Recognition, we can notice which action was taken by the motional data come from sensors like accelerometers. One application of such thing is helping people exercise for their safety. On this report, a model will be made for identifying which action is taken by motional data, and the model will be used for prediction.

## Data

The data was collected from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.

The data is consist of 159 predictors and the response variable 'classe'. The response variable has 5 possible values: "A", "B", "C", "D", and "E", and the values represent five different fashions when six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl.

* "A": exactly according to the specification
* "B": throwing the elbows to the front
* "C": lifting the dumbbell only halfway
* "D": lowering the dumbbell only halfway
* "E": throwing the hips to the front

More information can be found here: http://groupware.les.inf.puc-rio.br/har

The training data for this project are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

## Cleaning Data

```{r, message=FALSE}
library(dplyr)
library(caret)
set.seed(1234)
```

The data read from CSV files has many variables with a lot of NA values.

```{r}
training <- tbl_df(read.csv("data/pml-training.csv", na.strings = c("NA", "#DIV/0!")))
testing <- tbl_df(read.csv("data/pml-testing.csv", na.strings = c("NA", "#DIV/0!")))

length(names(training))  # 159 including the response variable
str(training$classe)

str(training)
```

To make a proper model, it needs to filter variables which has no NA value.

```{r}
filterVariables <- function (d, includeResponseVariable=FALSE) {
        # remove unneccessary variables
        d2 <- select(d, -(X:num_window))
        #str(d2)
        #summary(d2)
        
        if (includeResponseVariable) {
        # remove variables which has many NAs
        select(d2,  # 53 variables - response variable
                     roll_belt, pitch_belt, yaw_belt, total_accel_belt, gyros_belt_x,
                     gyros_belt_y, gyros_belt_z, accel_belt_x, accel_belt_y, accel_belt_z,
                     magnet_belt_x, magnet_belt_y, magnet_belt_z, roll_arm, pitch_arm,
                     yaw_arm, total_accel_arm, gyros_arm_x, gyros_arm_y, gyros_arm_z,
                     accel_arm_x, accel_arm_y, accel_arm_z, magnet_arm_x, magnet_arm_y,
                     magnet_arm_z, roll_dumbbell, pitch_dumbbell, yaw_dumbbell, total_accel_dumbbell,
                     gyros_dumbbell_x, gyros_dumbbell_y, gyros_dumbbell_z, accel_dumbbell_x, accel_dumbbell_y,
                     accel_dumbbell_z, magnet_dumbbell_x, magnet_dumbbell_y, magnet_dumbbell_z, roll_forearm,
                     pitch_forearm, yaw_forearm, total_accel_forearm, gyros_forearm_x, gyros_forearm_y,
                     gyros_forearm_z, accel_forearm_x, accel_forearm_y, accel_forearm_z, magnet_forearm_x,
                     magnet_forearm_y, magnet_forearm_z  # no classe
                     )
        } else {
        # remove variables which has many NAs
        select(d2,  # 53 variables
                     roll_belt, pitch_belt, yaw_belt, total_accel_belt, gyros_belt_x,
                     gyros_belt_y, gyros_belt_z, accel_belt_x, accel_belt_y, accel_belt_z,
                     magnet_belt_x, magnet_belt_y, magnet_belt_z, roll_arm, pitch_arm,
                     yaw_arm, total_accel_arm, gyros_arm_x, gyros_arm_y, gyros_arm_z,
                     accel_arm_x, accel_arm_y, accel_arm_z, magnet_arm_x, magnet_arm_y,
                     magnet_arm_z, roll_dumbbell, pitch_dumbbell, yaw_dumbbell, total_accel_dumbbell,
                     gyros_dumbbell_x, gyros_dumbbell_y, gyros_dumbbell_z, accel_dumbbell_x, accel_dumbbell_y,
                     accel_dumbbell_z, magnet_dumbbell_x, magnet_dumbbell_y, magnet_dumbbell_z, roll_forearm,
                     pitch_forearm, yaw_forearm, total_accel_forearm, gyros_forearm_x, gyros_forearm_y,
                     gyros_forearm_z, accel_forearm_x, accel_forearm_y, accel_forearm_z, magnet_forearm_x,
                     magnet_forearm_y, magnet_forearm_z, classe
                     )
        }
}

training <- filterVariables(training)

summary(training)
```

## Spliting Data

I'm going to split the data into training data and testing data with proportion of 6:4.

```{r}
#training <- sample_n(training, 200)  # remove this later

InTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
training_1 <- training[InTrain, ]
training_2 <- training[-InTrain, ]
```

## Training Model

I chose the prediction method as random forest and the training option as cross validation with 5 folds. Random forest algorithm is known to have good performance, so it is default algorithm in `train` function by the way.

```{r, cache=TRUE}
fit_model <- train(classe ~ ., data=training_1, method="rf",
                   trControl=trainControl(method="cv", number=5),
                   allowParallel=TRUE, verbose=FALSE)
print(fit_model)
```

## Testing Model

```{r}
fit_train = predict(fit_model, training_1)
confusionMatrix(training_1$classe, fit_train)
```

As the confusion matrix reads, the accuracy is 1, which is natural, and it's 95% confidence interval is $[0.9997,\ 1]$. So 95% confidence interval of in sample error rate will be $[0,\ 0.0003]$.

Almost always, in sample error rate is lower than out of sample error rate, so I expect the out of sample error rate will be above 0.

```{r}
fit_test = predict(fit_model, training_2)
confusionMatrix(training_2$classe, fit_test)
```

Checking the confusion matrix, the accuracy is 0.9916 and it's 95% confidence interval is $[0.9893,\ 0.9935]$, which is quite good performance. So 95% confidence interval of out of sample error rate will be $[0.0065,\ 0.0107]$.

## Prediction

Predicting with the final model with the data from `pml-testing.csv` file results like this:

```{r}
fit_prod <- predict(fit_model, testing)
fit_prod
```

